import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
# for Streamlit rebuild

st.set_page_config(page_title="Accueil", layout="wide")
st.title("ğŸ“Š Tableau de bord - Analyse des donnÃ©es")

# Chargement des donnÃ©es
df = pd.read_csv("data/Loan.csv")

# =============================
# ğŸ—ƒï¸ AperÃ§u du dataset
# =============================
with st.expander("ğŸ” AperÃ§u et description du dataset"):
    st.write("Ici nous affichons les premiÃ¨res lignes du dataset (Loan.csv) utilisÃ© dans le projet. ")
    st.write(" Cela permet de visualiser les colonnes principales, comprendre la structure des donnÃ©es et identifier les types de variables (numÃ©riques, catÃ©gorielles...). ")
    st.dataframe(df.head())
    st.subheader("ğŸ“ƒ Description statistique")
    st.write("Cette section fournit des statistiques descriptives pour chaque colonne numÃ©rique du dataset, telles que la moyenne, l'Ã©cart-type, les valeurs minimales et maximales...")
    st.write(df.describe())

# =============================
# ğŸ”— Matrice de corrÃ©lation
# =============================
with st.expander("ğŸ“Œ Matrice de corrÃ©lation"):
    st.write("Cette carte montre la corrÃ©lation entre les variables numÃ©riques. Plus la couleur est intense, plus la corrÃ©lation est forte.")
    st.write("Elle a permis :\n"
             "- D'identifier les relations linÃ©aires entre les variables (ex : LoanAmount et MonthlyPayment.)\n"
             "- De dÃ©tecter dâ€™Ã©ventuelles redondances ou des variables trÃ¨s influentes (comme RiskScore ou DebtToIncomeRatio.)\n"
             "- De guider la sÃ©lection des variables pour les modÃ¨les prÃ©dictifs.")
    correlation_matrix = df.corr(numeric_only=True)
    n = len(correlation_matrix)
    fig_width = max(12, n * 0.6)
    fig_height = max(8, n * 0.5)
    fig_corr, ax_corr = plt.subplots(figsize=(fig_width, fig_height))
    sns.heatmap(correlation_matrix, annot=True, fmt=".2f", cmap='coolwarm', vmin=-1, vmax=1, ax=ax_corr)
    ax_corr.set_title('Carte des corrÃ©lations', fontsize=14)
    plt.tight_layout()
    st.pyplot(fig_corr)

# =============================
# ğŸ“ˆ Distribution du RiskScore
# =============================
with st.expander("ğŸ“Š Distribution du RiskScore"):
    st.write("Cet histogramme montre la distribution des scores de risque parmi les clients.\n"
             "Il  permet de comprendre comment se rÃ©partit le niveau de risque des clients. On observe notamment deux pics : au niveau du RiskScore Ã©gale Ã  40 et des scores compris entre 50  et 60.")
    st.write("""
### â„¹ï¸ InterprÃ©tation de la distribution du RiskScore


-  **La majoritÃ© des clients** ont un RiskScore entre **45 et 55**, ce qui indique un **niveau de risque modÃ©rÃ©**.
-  La distribution nâ€™est pas parfaitement symÃ©trique : il y a **plus de clients lÃ©gÃ¨rement en dessous de 50** que trÃ¨s au-dessus.
-  Les clients avec un score supÃ©rieur Ã  **70** sont **rares** et reprÃ©sentent des **profils trÃ¨s risquÃ©s**.
- De mÃªme, les profils trÃ¨s sÃ»rs (RiskScore < 35) sont peu frÃ©quents.

**Conclusion :**  
La population des clients est majoritairement composÃ©e de profils Ã  **risque moyen**, avec peu de cas extrÃªmes. Cela peut aider Ã  mieux cibler les dÃ©cisions d'approbation de crÃ©dit ou de segmentation des offres.
""")

    fig_dist, ax_dist = plt.subplots(figsize=(8, 4))
    sns.histplot(df['RiskScore'], kde=True, bins=30, ax=ax_dist)
    ax_dist.set_title("Distribution du RiskScore")
    ax_dist.set_xlabel("RiskScore")
    ax_dist.set_ylabel("Nombre de clients")
    ax_dist.grid(True)
    st.pyplot(fig_dist)

# =============================
# ğŸ§© Clustering avec KMeans
# =============================
with st.expander("ğŸ§  Analyse de clusters (mÃ©thode du coude et visualisation)"):
    

    clustering_features = df[['RiskScore', 'DebtToIncomeRatio', 'NetWorth', 'AnnualIncome', 'LoanApproved']].dropna()
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(clustering_features)

    # MÃ©thode du coude
    st.write("""
    ### ğŸ” MÃ©thode du coude 

    La mÃ©thode du coude permet de **dÃ©terminer le nombre optimal de clusters** pour lâ€™algorithme KMeans.


    - Dans notre cas, on observe un coude autour de **k = 3**, ce qui suggÃ¨re que **3 groupes de clients distincts** permettent une bonne segmentation.
    - Ce choix est confirmÃ© par lâ€™analyse des groupes (`Cluster 0`, `Cluster 1`, `Cluster 2`) qui ont des comportements diffÃ©rents vis-Ã -vis de lâ€™approbation de prÃªt.

    âœ… Ce nombre est donc utilisÃ© pour la suite de lâ€™analyse de clustering.
    """)
    inertias = []
    for k in range(1, 10):
        kmeans = KMeans(n_clusters=k, random_state=42)
        kmeans.fit(X_scaled)
        inertias.append(kmeans.inertia_)

    fig_elbow, ax_elbow = plt.subplots(figsize=(8, 4))
    ax_elbow.plot(range(1, 10), inertias, marker='o')
    ax_elbow.set_xlabel('Nombre de clusters')
    ax_elbow.set_ylabel('Inertie (distortion)')
    ax_elbow.set_title('MÃ©thode du coude pour KMeans')
    ax_elbow.grid(True)
    st.pyplot(fig_elbow)

    # Visualisation des clusters (avec 3 clusters pour l'exemple)
    st.write("""
###  InterprÃ©tation dÃ©taillÃ©e du clustering KMeans

Lâ€™algorithme KMeans a segmentÃ© les clients en **3 clusters** (groupes) selon leurs caractÃ©ristiques financiÃ¨res (`RiskScore`, `NetWorth`, `DTI`, `AnnualIncome`, `LoanApproved`.).  




-  **Les clusters 0 & 1** regroupent des clients avec **profils financiers dÃ©favorables** (fort endettement, faible revenu, mauvais score de risque, etc.).  
  â†’ TrÃ¨s peu de prÃªts sont accordÃ©s, ce sont donc des **groupes Ã  surveiller de prÃ¨s**.

-  **Le cluster 2** contient la grande majoritÃ© des clients dont le prÃªt est approuvÃ©.  
  â†’ Ces clients reprÃ©sentent un **profil type "solvable" ou Ã  faible risque**, idÃ©al pour des offres de crÃ©dit ou de fidÃ©lisation.

####  Utilisation recommandÃ©e :
- Adapter les **stratÃ©gies marketing** ou les **offres** selon le cluster.
- Renforcer la **politique de scoring automatique** Ã  partir des caractÃ©ristiques les plus discriminantes (ex : DTI, NetWorth).
- Ã‰valuer le risque global du portefeuille client par segmentation.
""")

    kmeans = KMeans(n_clusters=3, random_state=42)
    df_clustered = clustering_features.copy()
    df_clustered['Cluster'] = kmeans.fit_predict(X_scaled)

    fig_cluster, ax_cluster = plt.subplots(figsize=(8, 6))
    sns.scatterplot(
        data=df_clustered, x='RiskScore', y='DebtToIncomeRatio',
        hue='Cluster', palette='Set1', s=60, ax=ax_cluster
    )
    ax_cluster.set_title("Visualisation des clusters : RiskScore vs DebtToIncomeRatio")
    ax_cluster.set_xlabel("RiskScore")
    ax_cluster.set_ylabel("DebtToIncomeRatio")
    ax_cluster.grid(True)
    st.pyplot(fig_cluster)
    
    
    
    

