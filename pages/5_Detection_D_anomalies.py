import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.ensemble import IsolationForest
from sklearn.preprocessing import StandardScaler

st.set_page_config(page_title="DÃ©tection d'anomalies", layout="wide")
st.title("ğŸš¨ DÃ©tection dâ€™anomalies avec Isolation Forest")

st.markdown("""
### ğŸ¯ Objectif gÃ©nÃ©ral de l'algorithme

La dÃ©tection des clients suspects (**potentiellement Ã  risque ou frauduleux**) en se basant sur leurs **caractÃ©ristiques financiÃ¨res** 
(Age, AnnualIncome, CreditScore, Experience, LoanAmount, LoanDuration, MonthlyIncome, NetWorth, InterestRate, 'MonthlyLoanPayment',
    TotalDebtToIncomeRatio, RiskScore), grÃ¢ce Ã  lâ€™algorithme dâ€™**Isolation Forest**, et visualiser les rÃ©sultats dans une **interface web interactive**.
""")

st.markdown("""
Cette page utilise **Isolation Forest** pour dÃ©tecter des clients potentiellement suspects Ã  partir de plusieurs variables financiÃ¨res.
""")

with st.expander("ğŸ“˜ DÃ©tails sur le modÃ¨le Isolation Forest", expanded=False):
    st.markdown("""
    - ğŸ” **Nous avons entraÃ®nÃ© un modÃ¨le d'Isolation Forest**, qui isole les points atypiques dans lâ€™espace de donnÃ©es.
    -  **RÃ©sultat** :
        - `anomaly_labels = -1` â†’ **Client suspect**
        - `anomaly_labels = 1` â†’ **Client normal**
    """)


# Chargement des donnÃ©es
df = pd.read_csv("data/Loan.csv")

# Variables utilisÃ©es pour la dÃ©tection
features = [
    'Age', 'AnnualIncome', 'CreditScore', 'Experience',
    'LoanAmount', 'LoanDuration', 'MonthlyIncome',
    'NetWorth', 'InterestRate', 'MonthlyLoanPayment',
    'TotalDebtToIncomeRatio', 'RiskScore'
]

# Nettoyage et normalisation
X = df[features].dropna()
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# ModÃ¨le Isolation Forest
iso_forest = IsolationForest(contamination=0.03, random_state=42)
anomaly_labels = iso_forest.fit_predict(X_scaled)

# Ajout des colonnes au DataFrame
df_anomaly = X.copy()
df_anomaly['AnomalyScore'] = iso_forest.decision_function(X_scaled)
df_anomaly['Anomaly'] = anomaly_labels

# ==========================
# ğŸ“Š Affichage du scatterplot
# ==========================
st.subheader("ğŸ“ˆ Visualisation des anomalies (RiskScore vs DTI)")
fig, ax = plt.subplots(figsize=(10, 6))
sns.scatterplot(
    data=df_anomaly,
    x='RiskScore',
    y='TotalDebtToIncomeRatio',
    hue='Anomaly',
    palette={1: "blue", -1: "red"},
    ax=ax
)
plt.title("DÃ©tection dâ€™anomalies : RiskScore vs Total DTI")
plt.xlabel("RiskScore")
plt.ylabel("Total Debt to Income Ratio")
plt.legend(title="Anomalie", labels=["Normal", "Anomalie"])
st.pyplot(fig)

with st.expander("â„¹ï¸ Explication de la visualisation", expanded=False):
    st.markdown("""
    - ğŸ“ **Chaque point reprÃ©sente un client**  
    - ğŸ§® **Axe X** : `RiskScore` (niveau de risque estimÃ© du client)  
    - ğŸ“Š **Axe Y** : `TotalDebtToIncomeRatio` (niveau dâ€™endettement total du client)  
    - ğŸ”µ Les **clients normaux** sont reprÃ©sentÃ©s en **bleu**  
    - ğŸ”´ Les **clients suspects** (anomalies dÃ©tectÃ©es) sont en **rouge**
    """)

# ==========================
# ğŸ” Top clients suspects
# ==========================
st.subheader("ğŸ” Top 10 clients suspects")
clients_suspects = df_anomaly[df_anomaly['Anomaly'] == -1]
clients_suspects = clients_suspects.sort_values(by='AnomalyScore')
st.dataframe(clients_suspects.head(10).style.format({"AnomalyScore": "{:.4f}"}))

# (Optionnel) Export
with st.expander("ğŸ“¥ TÃ©lÃ©charger les rÃ©sultats complets"):
    st.download_button(
        label="TÃ©lÃ©charger les anomalies (CSV)",
        data=clients_suspects.to_csv(index=False).encode('utf-8'),
        file_name="clients_suspects.csv",
        mime='text/csv'
    )

# ==========================
# ğŸ§ª Simulation dâ€™un nouveau client
# ==========================
st.subheader("ğŸ§ª Simulation : tester un nouveau client")

with st.form("simulation_form"):
    col1, col2, col3 = st.columns(3)

    with col1:
        age = st.number_input("Ã‚ge", min_value=18, max_value=100, value=35)
        experience = st.number_input("AnnÃ©es dâ€™expÃ©rience", min_value=0, max_value=80, value=10)
        credit_score = st.number_input("Credit Score", min_value=0.0, max_value=1.0, step=0.01, value=0.6)
        loan_amount = st.number_input("Montant du prÃªt", min_value=0.0, value=5000.0)

    with col2:
        loan_duration = st.number_input("DurÃ©e du prÃªt (mois)", min_value=1, value=24)
        interest_rate = st.number_input("Taux d'intÃ©rÃªt (%)", min_value=0.0, max_value=100.0, value=5.0)
        net_worth = st.number_input("Patrimoine net", min_value=0.0, value=10000.0)
        monthly_income = st.number_input("Revenu mensuel", min_value=0.0, value=3000.0)

    with col3:
        annual_income = st.number_input("Revenu annuel", min_value=0.0, value=36000.0)
        monthly_payment = st.number_input("Paiement mensuel du prÃªt", min_value=0.0, value=200.0)
        dti = st.number_input("Total Debt to Income Ratio", min_value=0.0, max_value=1.0, step=0.01, value=0.3)
        risk_score = st.number_input("Risk Score", min_value=0.0, max_value=1.0, step=0.01, value=0.5)

    submitted = st.form_submit_button("Analyser le client")

    if submitted:
        new_data = pd.DataFrame([[
            age, annual_income, credit_score, experience,
            loan_amount, loan_duration, monthly_income,
            net_worth, interest_rate, monthly_payment,
            dti, risk_score
        ]], columns=features)

        # Normalisation
        new_data_scaled = scaler.transform(new_data)

        # PrÃ©diction
        prediction = iso_forest.predict(new_data_scaled)[0]
        score = iso_forest.decision_function(new_data_scaled)[0]

        if prediction == -1:
            st.error(f"ğŸš¨ Ce client est dÃ©tectÃ© comme **suspect** (anomalie).")
        else:
            st.success("âœ… Ce client est considÃ©rÃ© comme **normal**.")

        st.markdown(f"**Score d'anomalie** : `{score:.4f}` (plus le score est nÃ©gatif, plus lâ€™anomalie est forte)")
